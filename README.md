There are two scripts of interest in this repository: data_generator.py and txt_learn.py

data_generator.py -- this script generates data to train the text-identification model with. First it splits up text files into 250 character chunks, then supplements each one with a random 250 character string and stores both in a database ('english-text.db').  Then, it will pickle a pandas dataframe with data on character frequencies for each block of text and store it in a file 'dataframe.pkl'.  Several command line options are included to customize the behavior of this script.  To see command line options and descriptions run ```python3 data_generator.py --help```

txt_learn.py -- this script takes the data generated by data_generator.py and uses it to train a sci-kit learn model, which is pickled into a file called 'model.pkl'.  This model can yield an estimated probability that a string is English and not random letters.  Like data_generator.py, this script includes several command line options to configure its behavior.  See all options and descriptions using ```python3 txt_learn.py --help```.

THe easiest way to generate a model and use it is by entering the following command:
```python3 txt_learn.py -g q,c -ti```
This will first generate the necessary data, then the model, then test the model for accuracy on the current data set and report results, then open an interactive command line interface which allows the user to calculate the estimated probaiblity of given strings being English.  An empty line exits the shell.